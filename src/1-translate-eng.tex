\section{Smart Health and Wellbeing (Умное здоровье и благополучие)}
Much like the big data opportunities facing the e-commerce
and S\&T communities, the health community is facing a
tsunami of health- and healthcare-related content generated
from numerous patient care points of contact, sophisticated
medical instruments, and web-based health communities.
Two main sources of health big data are genomics-driven big
data (genotyping, gene expression, sequencing data) and
payer–provider big data (electronic health records, insurance
records, pharmacy prescription, patient feedback and
responses)~\cite{Miller:2012a}. The expected raw sequencing data
from each person is approximately four terabytes. From the
payer–provider side, a data matrix might have hundreds of
thousands of patients with many records and parameters
(demographics, medications, outcomes) collected over a long
period of time. Extracting knowledge from health big data
poses significant research and practical challenges, especially
considering the HIPAA (Health Insurance Portability and
Accountability Act) and IRB (Institutional Review Board)
requirements for building a privacy-preserving and trustworthy
health infrastructure and conducting ethical healthrelated
research~\cite{Gelfand:2012}. Health big data analytics,
in general, lags behind e-commerce BI\&A applications
because it has rarely taken advantage of scalable analytical
methods or computational platforms~\cite{Miller:2012a}.

Over the past decade, electronic health records (EHR) have
been widely adopted in hospitals and clinics worldwide.
Significant clinical knowledge and a deeper understanding of
patient disease patterns can be gleanded from such collections
(Hanauer et al. 2009; Hanauer et al. 2011; Lin et al. 2011).
Hanauer et al. (2011), for example, used large-scale, longitudinal
EHR to research associations in medical diagnoses
and consider temporal relations between events to better
elucidate patterns of disease progression~\cite{Lin:2011}.
used symptom–disease–treatment (SDT) association rule
mining on a comprehensive EHR of approximately 2.1
million records from a major hospital. Based on selected
International Classification of Diseases (ICD-9) codes, they
were able to identify clinically relevant and accurate SDT
associations from patient records in seven distinct diseases,
ranging from cancers to chronic and infectious diseases.

In addition to EHR, health social media sites such as Daily
Strength and PatientsLikeMe provide unique research opportunities
in healthcare decision support and patient empowerment
~\cite{Miller:2012b}, especially for chronic diseases such as
diabetes, Parkinson’s, Alzheimer’s, and cancer. Association
rule mining and clustering, health social media monitoring
and analysis, health text analytics, health ontologies, patient
network analysis, and adverse drug side-effect analysis are
promising areas of research in health-related BI\&A. Due to
the importance of HIPAA regulations, privacy-preserving
health data mining is also gaining attention~\cite{Gelfand:2012}.

Partially funded by the National Institutes of Health (NIH),
the NSF BIGDATA program solicitation includes common
interests in big data across NSF and NIH. Clinical decision
making, patient-centered therapy, and knowledge bases for
health, disease, genome, and environment are some of the
areas in which BI\&A techniques can contribute~\cite{Chen:2011b}~\cite{Wactlar:2011}. Another recent, major NSF initiative
related to health big data analytics is the NSF Smart Health
and Wellbeing (SHB)6
program, which seeks to address
fundamental technical and scientific issues that would support
a much-needed transformation of healthcare from reactive and
hospital-centered to preventive, proactive, evidence-based,
person-centered, and focused on wellbeing rather than disease
control. The SHB research topics include sensor technology,
networking, information and machine learning technology,
modeling cognitive processes, system and process modeling,
and social and economic issues~\cite{Wactlar:2011}, most of
which are relevant to healthcare BI\&A.

\section{Security and Public Safety (Безопасность и общественное спокойствие)}
Since the tragic events of September 11, 2001, security
research has gained much attention, especially given the
increasing dependency of business and our global society on
digital enablement. Researchers in computational science,
information systems, social sciences, engineering, medicine,
and many other fields have been called upon to help enhance
our ability to fight violence, terrorism, cyber crimes, and other
cyber security concerns. Critical mission areas have been
identified where information technology can contribute, as
suggested in the U.S. Office of Homeland Security’s report
<<National Strategy for Homeland Security>>, released in 2002,
including intelligence and warning, border and transportation
security, domestic counter-terrorism, protecting critical infrastructure
(including cyberspace), defending against catastrophic
terrorism, and emergency preparedness and response.
Facing the critical missions of international security and
various data and technical challenges, the need to develop the
science of “security informatics” was recognized, with its
main objective being the development of advanced information technologies, systems, algorithms, and databases for securityrelated applications, through an integrated technological,
organizational, and policy-based approach~\cite{Chen:2006}.

BI\&A has much to contribute to the emerging field of security
informatics.

Security issues are a major concern for most organizations.
According to the research firm International Data Corporation,
large companies are expected to spend \$32.8 billion in
computer security in 2012, and small- and medium-size
companies will spend more on security than on other IT
purchases over the next three years~\cite{Perlroth:2012}.
In academia, several security-related disciplines such as
computer security, computational criminology, and terrorism
informatics are also flourishing~\cite{Brantingham:2011}.

Intelligence, security, and public safety agencies are gathering
large amounts of data from multiple sources, from criminal
records of terrorism incidents, and from cyber security threats
to multilingual open-source intelligence. Companies of different
sizes are facing the daunting task of defending against
cybersecurity threats and protecting their intellectual assets
and infrastructure. Processing and analyzing security-related
data, however, is increasingly difficult. A significant challenge
in security IT research is the information stovepipe and
overload resulting from diverse data sources, multiple data
formats, and large data volumes. Current research on technologies
for cybersecurity, counter-terrorism, and crimefighting
applications lacks a consistent framework for
addressing these data challenges. Selected BI\&A technologies
such as criminal association rule mining and clustering,
criminal network analysis, spatial-temporal analysis and
visualization, multilingual text analytics, sentiment and affect
analysis, and cyber attacks analysis and attribution should be
considered for security informatics research.
The University of Arizona’s COPLINK and Dark Web
research programs offer significant examples of crime data
mining and terrorism informatics within the IS community~\cite{Chen:2006}. The COPLINK information sharing and crime data mining system, initially developed with funding
from NSF and the Department of Justice, is currently in use
by more than 4,500 police agencies in the United States and
by 25 NATO countries, and was acquired by IBM in 2011.
The Dark Web research, funded by NSF and the Department
of Defense (DOD), has generated one of the largest known
academic terrorism research databases (about 20 terabytes of
terrorist web sites and social media content) and generated
advanced multilingual social media analytics techniques.
Recognizing the challenges presented by the volume and
complexity of defense-related big data, the U.S. Defense
Advanced Research Project Agency (DARPA) within DOD
initiated the XDATA program in 2012 to help develop computational
techniques and software tools for processing and
analyzing the vast amount of mission-oriented information for
defense activities. XDATA aims to address the need for
scalable algorithms for processing and visualization of
imperfect and incomplete data. The program engages applied
mathematics, computer science, and data visualization communities
to develop big data analytics and usability solutions
for warfighters.7
BI\&A researchers could contribute significantly
in this area.

\section{Text Analytics (Текстовая аналитика)}

A significant portion of the unstructured content collected by
an organization is in textual format, from e-mail communication
and corporate documents to web pages and social
media content. Text analytics has its academic roots in
information retrieval and computational linguistics. In information
retrieval, document representation and query processing
are the foundations for developing the vector-space
model, Boolean retrieval model, and probabilistic retrieval
model, which in turn, became the basis for the modern digital
libraries, search engines, and enterprise search systems
(Salton 1989). In computational linguistics, statistical natural
language processing (NLP) techniques for lexical acquisition,
word sense disambiguation, part-of-speech-tagging (POST),
and probabilistic context-free grammars have also become
important for representing text~\cite{Manning:1999}.
In addition to document and query representations, user
models and relevance feedback are also important in
enhancing search performance.
Since the early 1990s, search engines have evolved into
mature commercial systems, consisting of fast, distributed
crawling; efficient inverted indexing; inlink-based page
ranking; and search logs analytics. Many of these foundational
text processing and indexing techniques have been
deployed in text-based enterprise search and document
management systems in BI\&A 1.0.

Leveraging the power of big data (for training) and statistical
NLP (for building language models), text analytics techniques
have been actively pursued in several emerging areas,
including information extraction, topic models, questionanswering
(Q/A), and opinion mining. Information extraction
is an area of research that aims to automatically extract
specific kinds of structured information from documents. As
a building block of information extraction, NER (named
entity recognition, also known as entity extraction) is a
process that identifies atomic elements in text and classifies
them into predefined categories (e.g., names, places, dates).
NER techniques have been successfully developed for news
analysis and biomedical applications. Topic models are algorithms
for discovering the main themes that pervade a large
and otherwise unstructured collection of documents. New
topic modeling algorithms such as LDA (latent Dirichlet
allocation) and other probabilistic models have attracted
recent research~\cite{Blei:2012}. Question answering (Q/A) systems
rely on techniques from NLP, information retrieval, and
human–computer interaction. Primarily designed to answer
factual questions (i.e., who, what, when, and where kinds of
questions), Q/A systems involve different techniques for
question analysis, source retrieval, answer extraction, and
answer presentation~\cite{Maybury:2004}. The recent successes
of IBM’s Watson and Apple’s Siri have highlighted Q/A
research and commercialization opportunities. Many promising
Q/A system application areas have been identified,
including education, health, and defense. Opinion mining
refers to the computational techniques for extracting, classifying,
understanding, and assessing the opinions expressed in
various online news sources, social media comments, and
other user-generated contents. Sentiment analysis is often
used in opinion mining to identify sentiment, affect, subjectivity,
and other emotional states in online text. Web 2.0 and
social media content have created abundant and exciting
opportunities for understanding the opinions of the general
public and consumers regarding social events, political movements,
company strategies, marketing campaigns, and product
preferences~\cite{Pang:2008}.

In addition to the above research directions, text analytics also
offers significant research opportunities and challenges in
several more focused areas, including web stylometric
analysis for authorship attribution, multilingual analysis for
web documents, and large-scale text visualization. Multimedia
information retrieval and mobile information retrieval
are two other related areas that require support of text
analytics techniques, in addition to the core multimedia and
mobile technologies. Similar to big data analytics, text
analytics using MapReduce, Hadoop, and cloud services will
continue to foster active research directions in both academia
and industry.

\section{Web Analytics (Веб-аналитика)}

Over the past decade, web analytics has emerged as an active
field of research within BI\&A. Building on the data mining
and statistical analysis foundations of data analytics and on
the information retrieval and NLP models in text analytics,
web analytics offers unique analytical challenges and
opportunities. HTTP/HTML-based hyperlinked web sites and
associated web search engines and directory systems for
locating web content have helped develop unique Internetbased
technologies for web site crawling/spidering, web page
updating, web site ranking, and search log analysis. Web log
analysis based on customer transactions has subsequently
turned into active research in recommender systems. However,
web analytics has become even more exciting with the
maturity and popularity of web services and Web 2.0 systems
in the mid-2000s~\cite{OReilly:2005}. 

Based on XML and Internet protocols (HTTP, SMTP), web
services offer a new way of reusing and integrating third party
or legacy systems. New types of web services and their
associated APIs (application programming interface) allow
developers to easily integrate diverse content from different
web-enabled system, for example, REST (representational
state transfer) for invoking remote services, RSS (really
simple syndication) for news “pushing,” JSON (JavaScript
object notation) for lightweight data-interchange, and AJAX
(asynchronous JavaScript + XML) for data interchange and
dynamic display. Such lightweight programming models
support data syndication and notification and “mashups” of
multimedia content (e.g., Flickr, Youtube, Google Maps)
from different web sources—a process somewhat similar to
ETL (extraction, transformation, and load) in BI\&A 1.0.
Most of the e-commerce vendors have provided mature APIs
for accessing their product and customer content~\cite{Schonfeld:2005}. For example, through Amazon Web Services, developers
can access product catalog, customer reviews, site
ranking, historical pricing, and the Amazon Elastic Compute
Cloud (EC2) for computing capacity. Similarly, Google web
APIs support AJAX search, Map API, GData API (for
Calendar, Gmail, etc.), Google Translate, and Google App
Engine for cloud computing resources. Web services and
APIs continue to provide an exciting stream of new data
sources for BI\&A 2.0 research.

A major emerging component in web analytics research is the
development of cloud computing platforms and services,
which include applications, system software, and hardware
delivered as services over the Internet. Based on serviceoriented
architecture (SOA), server virtualization, and utility
computing, cloud computing can be offered as software as a service (SaaS), infrastructure as a service (IaaS), or platform
as a service (PaaS). Only a few leading IT vendors are currently
positioned to support high-end, high-throughput BI\&A
applications using cloud computing. For example, Amazon
Elastic Compute Cloud (EC2) enables users to rent virtual
computers on which to run their own computer applications.
Its Simple Storage Service (S3) provides online storage web
service. Google App Engine provides a platform for developing
and hosting Java or Python-based web applications.
Google Bigtable is used for backend data storage. Microsoft’s
Windows Azure platform provides cloud services such as
SQL Azure and SharePoint, and allows .Net framework
applications to run on the platform. The industry-led web and
cloud services offer unique data collection, processing, and
analytics challenges for BI\&A researchers.

In academia, current web analytics related research encompasses
social search and mining, reputation systems, social
media analytics, and web visualization. In addition, webbased
auctions, Internet monetization, social marketing, and
web privacy/security are some of the promising research
directions related to web analytics. Many of these emerging
research areas may rely on advances in social network analysis,
text analytics, and even economics modeling research.
