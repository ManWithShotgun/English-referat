\section{Smart Health and Wellbeing (Здравоохранение и благополучие)}
Подобно большим возможностям данных, с которыми сталкивается электронная коммерция и сообщество S\&T, так же сообщество здравоохранения сталкивается с
большим количеством медицинских и медицински связаннхы данных из многочисленных пунктов обслуживания пациентов, сложных
медицинских инструментов и веб-сообществ здравоохранения.
Двумя основными источниками медицинских данных являются большие геномики данных (генотипирование, экспрессия генов, данные секвенирования) и
большие данные от клиентов (электронные медицинские записи, страховые
записи, аптечные рецепты, отзывы пациентов и
ответы)~\cite{Miller:2012a}. Ожидаемые необработанные данные
от каждого человека - объёмом около четырех терабайт. Со стороны получатель-поставщик, матрица данных может иметь сотни
тысяч пациентов со многими записями и параметрами
(демография, медикаменты, результаты), собранные в течение длительного
периода времени. Извлечение знаний из больших данных о здоровье
ставит значительные исследовательские и практические задачи, особенно
учитывая HIPAA (переносимость медицинского страхования и
Закон о подотчетности) и IRB (Комиссия по институциональному обзору)
требования для создания конфиденциальности и надежности
инфраструктуры здравоохранения и обеспечения этического медицинского
исследования~\cite{Gelfand:2012}. Аналитика больших медицинских данных,
в целом, отстает от приложений электронной коммерции BI\&A
потому что они редко используют преимущества масштабируемых аналитических
методов или вычислительных платформ~\cite{Miller:2012a}.

За последнее десятилетие электронные медицинские записи (EHR)
широко применяется в больницах и клиниках по всему миру.
Значительные клинические знания и более глубокое понимание
видов болезней пациента могут быть оценены из таких сборников как
Hanauer et al., 2009; Hanauer et al., 2011; Lin et al., 2011.
Hanauer et al. (2011), например, использовали крупномасштабные продольные
EHR для исследования ассоциаций в медицинских диагнозах
и рассмотрения временных отношения между событиями к лучшему
выявлению закономерности прогрессирования заболевания~\cite{Lin:2011}.
Использовалось правило ассоциации с симптомами болезни (SDT)
 для получения полезных данных со всевозможных EHR записей, приблизительно 2.1
миллион записей из крупных больниц. На основе выбранных
Кодов международной классификации болезней (ICD-9), они
смогли идентифицировать клинически релевантные и точные SDT
ассоциации из записей пациентов в семи различных заболеваниях,
от рака до хронических и инфекционных заболеваний.

В дополнение к EHR, сайты социальных сетей здравоохранения, такие как Daily
Strength и PatientsLikeMe предоставляют уникальные возможности для исследований
в поддержке принятия решений в области здравоохранения и расширении прав и возможностей пациентов~\cite{Miller:2012b}, особенно для хронических заболеваний, таких как
диабета, болезни Паркинсона, болезни Альцгеймера и рака. Разработка
общих правил и кластеризация, мониторинг социальных сетей
и их анализ, аналитика по медицинским записям, анализ медицинских онтологий, анализ связей пациента и побочных эффектов наркотиков это
перспективные направления исследований в области здравоохранения и бизнеса. Из-за
важность правил HIPAA, сохранение конфиденциальности в
получение полезных данных также привлекает внимание~\cite{Gelfand:2012}.

Частично финансируемый Национальными институтами здравоохранения (NIH),
программа NSF BIGDATA включает в себя общие
интересы в больших данных через NSF и NIH. Клиническое решение
терапии, ориентированной на пациента, и базы знаний для
здоровья, болезней, геномов и окружающей среды является одним из
области, в которых BI\&A методы могут помочь~\cite{Chen:2011b}~\cite{Wactlar:2011}. Еще одна недавняя инициатива NSF
связанная с анализом больших данных для здравохранения - это NSF программы здравохранения и благополучия(SHB), в рамках которых
фундаментальные технические и научные вопросы, которые
столь необходимы для трансформации здравоохранения из реактивных и
ориентированных на медицинские данные на профилактические, основанные на фактических данных,
ориентированных на человека и ориентированных скорее на благополучие, чем на контроль болезний. Темы исследований SHB включают сенсорную технологию,
сети, информацию и технологии машинного обучения,
моделирование когнитивных процессов, моделирование систем и процессов,
и социально-экономические вопросы~\cite{Wactlar:2011}, большая часть
которые имеют отношение к здравоохранению BI\&A.

\section{Security and Public Safety (Безопасность и общественное спокойствие)}

После трагических событий 11 сентября 2001 года исследования безопасности получили много внимания, особенно учитывая
растущую зависимость бизнеса и нашего глобального общества от
цифрового включения. Исследователи вычислительной науки,
информационных систем, социальных наук, инженерии, медицины,
и многих других областей призваны помочь
нам бороться с насилием, терроризмом, киберпреступностью и другими
проблемы с кибербезопасности. Критические места информационных технологий были обозначены в докладе Управления национальной безопасности США
<<Национальная стратегия государственной безопасности >>, выпущенным в 2002 году,
включая разведку и обнаружение угроз, пограничную и транспортную
безопасность, внутреннюю борьбу с терроризмом, защиту критической инфраструктуры
(включая киберпространство), защищая от терроризма, готовности к чрезвычайным ситуациям и реагированию.
Обозначенные критические цели для международной безопасности и
различных данных и технических проблем, необходимость разработки
науки о «информационной безопасности» чьей главной задачей является развитие передовых информационных технологий, систем, алгоритмов и баз данных для приложений, связанных с безопасностью, при помощи интегрированных технологических,
организационных и политических подходов~\cite{Chen:2006}.

BI\&A может многое внести в новую область инфармационной безопасности.

Вопросы безопасности являются серьезной проблемой для большинства организаций.
По данным исследовательской фирмы International Data Corporation,
ожидается, что крупные компании потратят \$ 32,8 млрд. на
компьютерную безопасность в 2017 году, а также малые и средние
компании будут тратить больше средств на безопасность, чем на другие ИТ
покупки в течение следующих трех лет~\cite{Perlroth:2012}.
В академических кругах некоторые связанные с безопасностью дисциплины, такие как
компьютерная безопасность, вычислительная криминология и изучение
терроризма также востребованы~\cite{Brantingham:2011}.

Интелектуальная собственность, безопасность и общественная безопасность это большое количество данных из нескольких источников, от криминальных
отчетов о случаях терроризма и угрозах кибербезопасности
до многоязычной интелектуальной собственности с открытым исходным кодом. Компании разных
размеров сталкиваются с непростой задачей защиты от
угрозы кибербезопасности и защиты их интеллектуальных активов
и инфраструктуры. Обработка и анализ связанных с безопасностью данные все труднее. Значительная проблема
в области безопасности ИТ-исследований - это информационный <<чёрный ящик>> и большая сложность, возникающая из-за разных источников данных, множества форматов данных и больших объемов данных. В текущих исследованиях технологий
для кибербезопасности, борьбы с терроризмом и борьбы с преступностью
в проектах отсутствует согласованная структура для
решения этих проблем. Особенные технологии BI\&A
такие как криминальная ассоциация, управление и кластеризация,
анализ криминальной сети, пространственно-временной анализ и
визуализация, многоязычная текстовая аналитика, характеристический 
анализ окраски текста и анализ кибер-атак и их определение должны быть
рассмотренный для исследования информационной безопасности. Исследовательские программы университета Аризоны COPLINK и Dark Web предлагают примеры важных данных о преступности и террористических данных от сообществе IS~\cite{Chen:2006}. Система сбора информации о совместном использовании информации и преступности COPLINK, первоначально разработанная с финансированием
от NSF и Министерством юстиций, в настоящее время используется в
более 4500 полицейских агентствах в Соединенных Штатах и
25 стран НАТО, и была приобретена IBM в 2011 году.
Исследование Dark Web, финансируемое NSF и Департаментом
обороны (DOD), создало одну из самых больших известных
академических баз данных исследований терроризма (объёмом около 20 терабайт: террористических веб-сайтов и контента в социальных сетях) и
передовые многоязычные методы анализа социальных медиа.
Признавая проблемы, связанные с объемом и
сложностью больших данных, связанных с обороно - защита США
Агентство перспективных исследований (DARPA) в рамках DOD
инициировало программу XDATA в 2012 году, чтобы помочь разработать вычислительные
методы и программные средства для обработки и
анализ огромного количества информации ориентированной на использование в обороне. XDATA направлена ​​на удовлетворения потребностей в
масштабируемыех алгоритмах для обработки и визуализации
несовершенных и неполных данных. Программа применяется
математиками, информатиками и сообществом визуализации данных для
разработки анализа больших данных и удобства использования
их для военнослужащих.
BI\&A исследователи могли внести значительный вклад
в этой области.

\section{Text Analytics (Текстовая аналитика)}

Значительная часть неструктурированного контента, собранная
организацией в текстовом формате, от электронной почты
и корпоративных документов на веб-страницах до социального
медиаконтента. Текстовая аналитика имеет свои академические корни в поиске информации и вычислительной лингвистики. Для
поиска информации представление документов и обработка запросов
являются основой для разработки векторного пространства
модели, модель булевых поисковиков и модель вероятностного поиска, которая, в свою очередь, стала основой для современной цифровой
библиотеки, поисковых систем и поисковых систем предприятий
~\cite{Salton:1989}. В вычислительной лингвистике существуют статистические 
методы обработки естественного языка (NLP) для лексического значения,
смыслового значения слова, частоты речи (POST)
и вероятностных контекстно-свободных правил также стали
важными для представления текста~\cite{Manning:1999}.
Также предоставление документов и модели запросов пользователей и релевантность обратной связи для
повышенной эффективности поиска также важны.
С начала 1990-х годов поисковые системы превратились в
зрелые коммерческие системы, состоящие из быстрых, распределенных
систем, эффективной инвертированной индексации; ранжирования основанного на ссылках; и аналитики поисковых запросов. Многие из этих основополагающих
методы обработки текста и индексирования были
развернуты в текстовом поиске предприятия и документах
систем управления в BI\&A 1.0.

Использование мощности больших данных (для обучения) и статистических
NLP (для создания языковых моделей), методы текстовой аналитики
активно проводились в нескольких новых областях,
включая извлечение информации, построения тематических моделей, опросах
(Q/A) и интеллектуального анализа. Извлечение информации
является областью исследований, целью которых является автоматическое извлечение
конкретных видов структурированной информации из документов. Извлечения информации в виде
строительных блок, NER (метод назвающийся
<<распознавание объектов>>, также известный как извлечение сущности) является
процесс, который идентифицирует неделимые элементы в тексте и классифицирует
их в предопределенные категории (например, имена, места, даты).
Технологии NER были успешно разработаны для новостного
анализа и биомедицинских приложений. Тематические модели - это алгоритмы
для раскрытия основных тем, которых больше всего
и в противном случае получается неструктурированный сбор документов. Новые
алгоритмы моделирования тем, такие как LDA (latent Dirichlet
allocation) и другие вероятностные модели
недавних исследований~\cite{Blei:2012}. Системы ответа на вопрос (Q/A)
полагатся на методы из NLP, на поиск информации и
взаимодействие человека с компьютером. Прежде всего, чтобы ответить на
фактические вопросы (то есть, кто, что, когда и где
вопросы), системы Q/A включают различные методы для
анализ вопросов, поиска источников, извлечения ответов~\cite{Maybury:2004}. Недавние успехи
IBM Watson и Apple Siri выделили
возможности исследований и коммерциализации в Q/A. Были определены многообещающие области применения систем Q/A,
включая образование, здравоохранение и оборону. Извлечение вычислительными методами знаний, классификации,
понимания и оценки мнений выраженных в
различные онлайн-источниках новостей, комментариях в социальных сетях и в
другом пользовательском содержимом. Анализ настроений часто
используется в интеллектуальном анализе для выявления настроений, эффектов, субъективности,
и других эмоциональных состояний в онлайн-тексте. Web 2.0 и
социальный медиа-контент создал множество богатых и интересных
возможностей для понимания общего мнения
общественности и потребителей в отношении социальных событий, политических движений,
стратегий компаний, маркетинговых кампаний и предпочтения продуктов~\cite{Pang:2008}.

В дополнение к вышеуказанным направлениям исследование текстового анализа также
предлагает значительные исследовательские возможности и проблемы в
несколько более узконаправленных областях, включая веб-стилометрический
анализ авторства, многоязычный анализ для
веб-документов и широкомасштабную визуализацию текста. Мультимедийный
поиск информации и поиск мобильной информации
это две другие связанные области, которые требуют поддержки текст-аналитических методов, в дополнение к основным мультимедийным и
мобильным технологиям. Подобно аналитике больших данных,
аналитики текста с использованием MapReduce, Hadoop и облачных сервисов
продолжает улучшать активные направления исследований в обеих академических и промышленных кругах.

\section{Web Analytics (Веб-аналитика)}

За последнее десятилетие веб-аналитика стала активной
областью исследований в BI\&A. Основываясь на данных
и основах статистического анализа, аналитика данных и
модели поиска информации и NLP в текстовой аналитике,
веб-аналитика предлагает уникальные аналитические задачи и
возможности. HTTP/HTML-гиперссылки веб-сайтов и
ассационные поисковые системы и системы каталогов для
размещение веб-контента помогли разработать уникальный интернет технологий для обхода/паутинга веб-сайта, веб-страницы обновлений, ранжирование веб-сайтов и анализа поисковых запросов. Веб-журналы
анализа, основанные на транзакциях с клиентами, впоследствии
превратились в активные исследования для рекомендательных систем. Однако,
веб-аналитика стала еще более захватывающей с
ростом и популярностью веб-сервисов и систем Web 2.0
в середине 2000-х годов~\cite{OReilly:2005}.

На основе XML и интернет-протоколов (HTTP, SMTP), web
услуги предлагают новый способ повторного использования и интеграции сторонних
или устаревших систем. Новые типы веб-сервисов и их
ассоциированные API (интерфейс прикладного программирования) позволяют
разработчикам легко интегрировать разнообразный контент из разных
веб-система, например, REST (репрезентативная
передача состояния) для вызова удаленных сервисов, RSS (на самом деле
простое синдицирование) для новостей «pushing», JSON (JavaScript
объектная нотация) для облегчения обмена данными и AJAX
(асинхронный JavaScript + XML) для обмена данными и
динамическим отображением. Такие легкие модели программирования
поддерживают сбор данных и уведомлений и коллекций
мультимедийного контента (например, Flickr, Youtube, Google Maps)
из разных веб-источников - процесс, несколько схожий с
ETL (извлечение, преобразование и загрузка) в BI\&A 1.0.
Большинство поставщиков электронной коммерции предоставили готовые API-интерфейсы
для доступа к их продукту и клиентскому контенту~\cite{Schonfeld:2005}. Например, через Amazon Web Services разработчики
могут получить доступ к каталогу продукции, отзывам клиентов, сайту
ранжирования, истории цен и Amazon Elastic Compute
Cloud (EC2) вычислительным ресурсам. Аналогичным образом, веб-сайт Google
API поддерживают поиск AJAX, API карт, API GData (для
Calendar, Gmail и т. д.), Google Translate и приложение Google Engine для облачных вычислительных ресурсов. Веб-службы и
API продолжают предоставлять захватывающий поток новых данных, которые являются
источниками для исследования BI\&A 2.0.

Одним из основных компонентов анализа веб-аналитики является
разработка облачных вычислительных платформ и сервисов,
которые включают приложения, системное программное обеспечение и аппаратное обеспечение
предоставляемых как услуги через Интернет. На основе сервисно-ориентированной
архитектуры (SOA), виртуализации серверов и вычисленых утилит, облачные вычисления могут предлагать программное обеспечение как услугу (SaaS), инфраструктуру как услугу (IaaS) или платформу
как услугу (PaaS). В настоящее время только несколько ведущих поставщиков ИТ-услуг
позиционируется для поддержки высоконагруженных высокопроизводительных BI\&A
приложений с использованием облачных вычислений. Например, Amazon
Elastic Compute Cloud (EC2) позволяет пользователям арендовать виртуальные
компьютеры, на которых позволено запускать собственные компьютерные приложения.
Их простая служба хранения (S3) оказывает услугу предоставления онлайн-хранилища. Google App Engine предоставляет платформу для разработки
и хостинга веб-приложений на основе Java или Python.
Google Bigtable используется для хранения данных на серверах. Microsoft's Windows Azure платформа предоставляет облачные сервисы, такие как
SQL Azure и SharePoint, а также позволяет .Net framework
приложениям работать на данной платформе. Отраслевая сеть и
облачные сервисы предлагают уникальные методики сбора, обработки и
аналитически для исследовательских задач BI\&A.

В академических кругах текущие исследования, связанные с веб-аналитикой, охватывают
поиск в социальном контенте и поиск полезных данных, систем отзывов, социальная
медиа-аналитика и веб-визуализация. Кроме того, веб-сайт
аукционы, интернет-монетизация, социальный маркетинг и
конфиденциальность/безопасность в Интернете - вот некоторые из перспективных направлений исследований связанныех с веб-аналитикой. Многие из этих
исследовательских областей могут полагаться на успехи в анализе социальных сетей,
текстовой аналитики и даже исследований экономического моделирования.
